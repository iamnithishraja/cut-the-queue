services:
  zookeeper:
    image: confluentinc/cp-zookeeper:latest
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_INIT_LIMIT: 10
    ports:
      - 2181:2181
    healthcheck:
      test:
        [
          "CMD",
          "echo",
          "ruok",
          "|",
          "nc",
          "localhost",
          "2181",
          "|",
          "grep",
          "imok",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always

  #Service: kafka
  kafka:
    image: confluentinc/cp-kafka:latest
    depends_on:
      zookeeper:
        condition: service_healthy
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092,PLAINTEXT_HOST://localhost:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_LOG_RETENTION_MS: 86400000 # 24 hours in milliseconds
      KAFKA_LOG_CLEANUP_POLICY: delete
    ports:
      - 9092:9092
      - 29092:29092
    healthcheck:
      test:
        [
          "CMD",
          "kafka-topics",
          "--list",
          "--bootstrap-server",
          "localhost:9092",
        ]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: always

  #Service: kafka-init
  kafka-init:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
    environment:
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
    entrypoint: >
      bash -c "
      echo 'Waiting for Kafka to be ready...'; 
      while ! nc -z kafka 9092; do sleep 1; done;
      echo 'Kafka is ready, creating topics...'; 
      kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic sms --if-not-exists && 
      kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic email --if-not-exists &&
      kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic notification --if-not-exists;
      echo 'Kafka topics created.'"
    healthcheck:
      test:
        [
          "CMD",
          "kafka-topics",
          "--describe",
          "--topic",
          "sms",
          "--bootstrap-server",
          "localhost:9092",
        ]
      interval: 10s
      timeout: 5s
      retries: 5

  #Service: sms-consumer
  sms-consumer:
    depends_on:
      kafka:
        condition: service_healthy
    build:
      context: ./
      dockerfile: ./apps/consumers/Dockerfile
      platforms:
        - linux/amd64
    environment:
      TWO_FACTOR_API_KEY: ${TWO_FACTOR_API_KEY}
      KAFKA_BROKER: kafka:9092
      KAFKA_CLIENT_ID: sms-consumer
      CONSUMER_TYPE: sms
      BUN_ENV: production # Added for Bun
    restart: always

  email-consumer:
    depends_on:
      kafka:
        condition: service_healthy
    build:
      context: ./
      dockerfile: ./apps/consumers/Dockerfile
      platforms:
        - linux/amd64
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_CLIENT_ID: email-consumer
      CONSUMER_TYPE: email
      BUN_ENV: production # Added for Bun
    env_file:
      - .env
    restart: always

  #Service: notification-consumer
  notification-consumer:
    depends_on:
      kafka:
        condition: service_healthy
    build:
      context: ./
      dockerfile: ./apps/consumers/Dockerfile
      platforms:
        - linux/amd64
    environment:
      KAFKA_BROKER: kafka:9092
      KAFKA_CLIENT_ID: notification-consumer
      CONSUMER_TYPE: notification
      BUN_ENV: production # Added for Bun
    env_file:
      - .env
    restart: always

  #Service: kafka-cleanup
  kafka-cleanup:
    image: confluentinc/cp-kafka:latest
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
      while true; do
        echo 'Clearing Kafka data...';
        kafka-topics --bootstrap-server kafka:9092 --list | xargs -I {} kafka-topics --bootstrap-server kafka:9092 --delete --topic {};
        echo 'Kafka data cleared. Recreating topics...';
        kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic sms --if-not-exists;
        kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic email --if-not-exists;
        kafka-topics --create --bootstrap-server kafka:9092 --replication-factor 1 --partitions 1 --topic notification --if-not-exists;
        echo 'Kafka topics recreated. Sleeping for 24 hours...';
        sleep 86400;
      done"
    restart: always

  # Service: Redis-pubsub
  redis-pubsub:
    image: redis/redis-stack-server:7.2.0-v6
    ports:
      - 6379:6379
    env_file:
      - .env
    environment:
      - REDIS_ARGS=--requirepass ${REDIS_PASSWORD}
    healthcheck:
      test: ["CMD", "redis-cli", "-a", "${REDIS_PASSWORD}", ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    restart: always
  #Service: http-server
  http-server:
    depends_on:
      kafka:
        condition: service_healthy
      redis-pubsub:
        condition: service_healthy
    build:
      context: ./
      dockerfile: ./apps/http/Dockerfile
      platforms:
        - linux/amd64
    environment:
      PORT: 3002
      KAFKA_CLIENT_ID: http-server
      KAFKA_BROKER: kafka:9092
      REDIS_PUB_SUB_URL: redis://redis-pubsub:6379
      REDIS_CHANNEL: "sockets"
      CLOUDFLARE_R2_ACCESS_KEY_ID: 8631e4cf2863839fe675692854c5a8ae
      CLOUDFLARE_R2_SECRET_ACCESS_KEY: b3ffa8b85326886b5297108c78b25c7aa9ae8b97ba609781832daf098d70caec
      CLOUDFLARE_R2_BUCKET_NAME: cut-the-q
      CLOUDFLARE_R2_ENDPOINT: https://d6dd68003d94fc1d5591a75b45ed25d8.r2.cloudflarestorage.com
      CLOUDFLARE_R2_PUBLIC_URL: https://pub-4c4ca315ecae4f0bb055b6a7886c8eef.r2.dev
      BUN_ENV: production # Added for Bun
    env_file:
      - .env
    ports:
      - 3002:3002
    restart: always

  # Service: socket-server
  socket-server:
    depends_on:
      redis-pubsub:
        condition: service_healthy
    build:
      context: ./
      dockerfile: ./apps/socket/Dockerfile
      platforms:
        - linux/amd64
    environment:
      PORT: 3001
      REDIS_HOST: redis-pubsub
      REDIS_PORT: 6379
      REDIS_CHANNEL: "sockets"
      BUN_ENV: production # Added for Bun
    env_file:
      - .env
    ports:
      - 3001:3001
    restart: always

  # Service: prometheus
  prometheus:
    image: prom/prometheus:latest
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"

  # Service: pushgateway
  pushgateway:
    image: prom/pushgateway:latest
    ports:
      - "9091:9091"
